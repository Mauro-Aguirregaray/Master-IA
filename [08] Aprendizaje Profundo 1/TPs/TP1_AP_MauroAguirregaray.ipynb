{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP1 Aprendizaje Profundo\n",
    "\n",
    "Se desea construir un sistema de recomendación de películas. Para esto se cuenta con un dataset de las puntuaciones que los usuarios han asignado a las peliculas disponibles.\n",
    "\n",
    "Link dataset: https://drive.google.com/file/d/1Og9H-8oqb3_Wo_WOakeAuRR_mwr922Ar/view?usp=sharing\n",
    "\n",
    "Para verificar la factibilidad del proyecto con datos válidos, se decide utilizar solamente las 200 películas con más votos y sobre eso los usuarios que han puntuado al menos 100 películas.\n",
    "\n",
    "1- Analizar el dataset para utilizar solamente las 200 películas con mayor cantidad de votos y los usuarios que hayan votado al menos 100 películas.\n",
    "\n",
    "2- A partir del dataset del punto 1, construir una única red neuronal que utilice una capa de embeddings para el id de usuario, una capa de embeddings para el id de película y al menos dos capas lineales que sea capaz de predecir el puntaje que cada usuario colocó a cada pelicula. Usar tecnicas de normalizacion en caso de ser necesario.\n",
    "\n",
    "3- Graficar las evoluciones de las funciones de costo en entrenamiento y validacion, como asi tambien las metricas de validacion. Explicar los resultados obtenidos.\n",
    "\n",
    "4- Construir una funcion capaz de recibir un usuario al azar, una cantidad \"p\" de películas que dicho usuario haya puntuado y verificar la predicción del modelo. Comparar con los puntajes reales contra los que el usuario asignó a dicha/s película/s.\n",
    "\n",
    "5- Contruir una funcion capaz de realizar una recomendación de película para un usuario determinado utilizando los embeddings de usuario o los embeddings de películas. Comprobar si la recomendación es correcta haciendo una predicción del puntuaje con la red neuronal.\n",
    "\n",
    "6- Con el mejor modelo obtenido del punto 2, elegir al menos 3 hiperparametros y aplicar algun metodo de tuneo. Explicar resultados obtenidos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Análisis exploratorio\n",
    "\n",
    "Primero analicemos el dataset y preparemos los datos para el entrenamiento con aprendizaje profundo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar el dataset\n",
    "movies_df = pd.read_csv(\"./datasets/ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>100836.000000</td>\n",
       "      <td>1.008360e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>326.127564</td>\n",
       "      <td>19435.295718</td>\n",
       "      <td>3.501557</td>\n",
       "      <td>1.205946e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>182.618491</td>\n",
       "      <td>35530.987199</td>\n",
       "      <td>1.042529</td>\n",
       "      <td>2.162610e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.281246e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>177.000000</td>\n",
       "      <td>1199.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.019124e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>325.000000</td>\n",
       "      <td>2991.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.186087e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>477.000000</td>\n",
       "      <td>8122.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.435994e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>193609.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.537799e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              userId        movieId         rating     timestamp\n",
       "count  100836.000000  100836.000000  100836.000000  1.008360e+05\n",
       "mean      326.127564   19435.295718       3.501557  1.205946e+09\n",
       "std       182.618491   35530.987199       1.042529  2.162610e+08\n",
       "min         1.000000       1.000000       0.500000  8.281246e+08\n",
       "25%       177.000000    1199.000000       3.000000  1.019124e+09\n",
       "50%       325.000000    2991.000000       3.500000  1.186087e+09\n",
       "75%       477.000000    8122.000000       4.000000  1.435994e+09\n",
       "max       610.000000  193609.000000       5.000000  1.537799e+09"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>3.0</td>\n",
       "      <td>964982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>101</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964980868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>110</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>157</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964984100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0       1        1     4.0  964982703\n",
       "1       1        3     4.0  964981247\n",
       "2       1        6     4.0  964982224\n",
       "3       1       47     5.0  964983815\n",
       "4       1       50     5.0  964982931\n",
       "5       1       70     3.0  964982400\n",
       "6       1      101     5.0  964980868\n",
       "7       1      110     4.0  964982176\n",
       "8       1      151     5.0  964984041\n",
       "9       1      157     5.0  964984100"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100836 entries, 0 to 100835\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     100836 non-null  int64  \n",
      " 1   movieId    100836 non-null  int64  \n",
      " 2   rating     100836 non-null  float64\n",
      " 3   timestamp  100836 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estamos en frente a un dataset con tan solo 4 features y una gran cantidad de entradas (100836). En particular se observan dos features \"userID\" y \"movieID\" que hacen referencia a usuarios X y películas Y respectivamente. Es un caso donde estos features si bien son numéricos se refieren más correctamente a variables categoricas, por lo que el uso de la herramienta de embeddings resulta de mucha utilidad.\n",
    "\n",
    "Además de estos features \"rating\" es un flotante que va de 0 a 5 (y el feature objetivo en este caso) y \"timestamp\" parece ser una medida de cuando fue subida la review que a nivel lógico no parecería aportar mucha información"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo a lo que pide el problema debemos filtrar el dataset para quedarnos solo con las 200 películas más votadas y sobre esas con los usuarios que hayan votado más de 100 películas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 25764 entries, 0 to 100452\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   userId     25764 non-null  int64  \n",
      " 1   movieId    25764 non-null  int64  \n",
      " 2   rating     25764 non-null  float64\n",
      " 3   timestamp  25764 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 1006.4 KB\n"
     ]
    }
   ],
   "source": [
    "#Filtrar las 200 películas más rateadas\n",
    "\n",
    "#Cuento las instancias de cada película\n",
    "value_counts_movies = movies_df[\"movieId\"].value_counts()\n",
    "\n",
    "#Guardo los id de las 200 películas con más ratings\n",
    "top_200_movies = value_counts_movies.head(200).index\n",
    "\n",
    "#Filtro el dataset para que solo contenga estas películas\n",
    "movies_df = movies_df[movies_df[\"movieId\"].isin(top_200_movies)]\n",
    "\n",
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "movieId\n",
       "356     329\n",
       "318     317\n",
       "296     307\n",
       "593     279\n",
       "2571    278\n",
       "       ... \n",
       "3897     83\n",
       "1101     83\n",
       "16       82\n",
       "788      82\n",
       "1584     82\n",
       "Name: count, Length: 200, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chequeo que mi dataset solo contenga 200 películas diferentes\n",
    "movies_df[\"movieId\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Misma idea pero para los usuarios ahora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filtrar los 100 usuarios que más reviews tienen\n",
    "\n",
    "#Cuento la cantidad de reviews por user\n",
    "value_counts_users = movies_df[\"userId\"].value_counts()\n",
    "\n",
    "#Guardo los id de las 100 users con más reviewss\n",
    "top_users = value_counts_users[value_counts_users>99].index\n",
    "\n",
    "#Filtro el dataset para que solo contenga estos usuarios\n",
    "movies_df = movies_df[movies_df[\"userId\"].isin(top_users)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "userId\n",
       "414    194\n",
       "599    189\n",
       "68     185\n",
       "480    177\n",
       "474    173\n",
       "      ... \n",
       "200    104\n",
       "453    103\n",
       "166    102\n",
       "603    102\n",
       "354    100\n",
       "Name: count, Length: 63, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Chequeo que no hayan quedado usuarios con menos de 100 reviews dentro del dataset\n",
    "movies_df[\"userId\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 8329 entries, 1772 to 100452\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   userId     8329 non-null   int64  \n",
      " 1   movieId    8329 non-null   int64  \n",
      " 2   rating     8329 non-null   float64\n",
      " 3   timestamp  8329 non-null   int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 325.4 KB\n"
     ]
    }
   ],
   "source": [
    "movies_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Separación Train-Test-Validation\n",
    "\n",
    "Separamos en train test el dataset, también me quito timestamp porque considero que no aporta información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo user_id para modelo con embeddings\n",
    "user_id = movies_df['userId']\n",
    "\n",
    "# Guardo movie_id para modelo con embeddings\n",
    "movie_id = movies_df['movieId']\n",
    "\n",
    "X = movies_df.drop(columns=[\"rating\",\"timestamp\"]).values\n",
    "y = movies_df[\"rating\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separamos en los sets de entrenamiento y evaluación\n",
    "X_train, X_test, y_train, y_test, train_idx, test_idx = train_test_split(X, y,np.arange(X.shape[0]), test_size = 0.20, random_state = 42)\n",
    "\n",
    "#Separamos sobre el set de entrenamiento, un subset de validación\n",
    "X_train, X_valid, y_train, y_valid, train_idx, valid_idx = train_test_split(X_train, y_train, train_idx, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8329"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train = X_train.shape[0]\n",
    "n_test = X_test.shape[0]\n",
    "n_valid = X_valid.shape[0]\n",
    "\n",
    "#Chequeamos que el total de datos está comprendido en la separación\n",
    "n_test+n_train+n_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformo user id a indices (idx) consecutivos para utilizar embeddings\n",
    "user_id_to_idx = {value:i for i,value in enumerate(user_id.unique())}\n",
    "\n",
    "# Transformo user id a indices (idx) consecutivos para utilizar embeddings\n",
    "movie_id_to_idx = {value:i for i,value in enumerate(movie_id.unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector de user_idx en el dataset\n",
    "user_idx = np.array([user_id_to_idx[value] for value in user_id])\n",
    "\n",
    "# Vector de movie_idx en el dataset\n",
    "movie_idx = np.array([movie_id_to_idx[value] for value in movie_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divido el vector user_idx en entrenamiento y validación\n",
    "user_idx_train = user_idx[train_idx]\n",
    "user_idx_valid = user_idx[valid_idx]\n",
    "\n",
    "# Divido el vector movie_idx en entrenamiento y validación\n",
    "movie_idx_train = movie_idx[train_idx]\n",
    "movie_idx_valid = movie_idx[valid_idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch necesita de una clase de dataset que extienda de torch.utils.data.Dataset\n",
    "# Esta clase dataset debe sobreescribir los métodos init, len y getitem\n",
    "class MyDatasetWithEmbddings(Dataset):\n",
    "\n",
    "  #__init__ guarda el dataset en una variable de clase\n",
    "  def __init__(self, x, user_idx, movie_idx, y):\n",
    "    self.x = x\n",
    "    self.user_idx = user_idx\n",
    "    self.movie_idx = movie_idx\n",
    "    self.y = y\n",
    "\n",
    "  # __len__ define el comportamiento de la función len() sobre el objeto\n",
    "  def __len__(self):\n",
    "    return self.x.shape[0]\n",
    "\n",
    "  # __getitem__ define el comportamiento de los []\n",
    "  def __getitem__(self, idx):\n",
    "    return self.x[idx], self.user_idx[idx], self.movie_idx[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el dataset de entrenamiento\n",
    "df_train = MyDatasetWithEmbddings(X_train, user_idx_train, movie_idx_train, y_train)\n",
    "# Creo el dataset de validación\n",
    "df_valid = MyDatasetWithEmbddings(X_valid, user_idx_valid, movie_idx_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch utiliza DataLoader para entregar los dataset de a batches\n",
    "train_dataloader = DataLoader(df_train, batch_size = 64, shuffle= True)\n",
    "valid_dataloader = DataLoader(df_valid, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos que definir la arquitectura de nuestra red neuronal. De acuerdo a lo que pide el ejercicio tenemos que definir una capa de embedding por feature y luego dos capas lineales.\n",
    "\n",
    "En particular y como no tengo referencia del problema voy a usar una regla empirica para definir la dimensionalidad de la capa de embeddings, en particular tomar aproximadamente la raíz cuadrada de la cantidad de instancias distintas. Esto es 14 para moviesId y 8 para userId.\n",
    "\n",
    "En cuanto a las capas lineales mantendré las estándar mostradas en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arquitectura con embeddings\n",
    "class NNetWithEmbeddings(torch.nn.Module):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.embeddings_user = torch.nn.Embedding(num_embeddings=63, embedding_dim=8)\n",
    "    self.embeddings_movie = torch.nn.Embedding(num_embeddings=200, embedding_dim=14)\n",
    "    self.linear_1 = torch.nn.Linear(in_features=14+8, out_features=200, bias=True)\n",
    "    self.relu_1 = torch.nn.ReLU()\n",
    "    self.linear_2 = torch.nn.Linear(in_features = 200, out_features=100, bias=True)\n",
    "    self.relu_2 = torch.nn.ReLU()\n",
    "    self.output = torch.nn.Linear(in_features = 100, out_features= 1, bias=True)\n",
    "\n",
    "  def forward(self, x, user_idx, movie_idx):\n",
    "    embeddings_outputs_user = self.embeddings_user(user_idx)\n",
    "    embeddings_outputs_movie =self.embeddings_movie(movie_idx)\n",
    "    x = torch.cat([x, embeddings_outputs_user, embeddings_outputs_movie], dim=1)\n",
    "    x = self.linear_1(x)\n",
    "    x = self.relu_1(x)\n",
    "    x = self.linear_2(x)\n",
    "    x = self.relu_2(x)\n",
    "    x = self.output(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:11.8'"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:11.8\"\n",
    "\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inicializo mi red\n",
    "nnnetWithEmbeddings = NNetWithEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
